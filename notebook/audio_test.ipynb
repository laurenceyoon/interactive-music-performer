{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import pyaudio\n",
    "import queue\n",
    "from typing import Optional\n",
    "import numpy as np\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "from collections import deque\n",
    "\n",
    "SAMPLE_RATE = 22050\n",
    "HOP_LENGTH = 256\n",
    "CHANNELS = 1\n",
    "N_FFT = 512\n",
    "feature_rate = int(SAMPLE_RATE / HOP_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StreamProcessor:\n",
    "    def __init__(self, sample_rate=SAMPLE_RATE, chunk_size=1024, verbose=True):\n",
    "        self.chunk_size = chunk_size\n",
    "        self.channels = CHANNELS\n",
    "        self.sample_rate = sample_rate\n",
    "        self.verbose = verbose\n",
    "        self.format = pyaudio.paFloat32\n",
    "        self.audio_interface: Optional[pyaudio.PyAudio] = None\n",
    "        self.audio_stream: Optional[pyaudio.Stream] = None\n",
    "        self.buffer = queue.Queue()\n",
    "        self.chroma_buffer = queue.Queue()\n",
    "        self.last_chunk = None\n",
    "        self.is_mic_open = False\n",
    "        self.index = 0\n",
    "\n",
    "    def _process_frame(self, data, frame_count, time_info, status_flag):\n",
    "        print(f'\\nprocess_frame index: {self.index}')\n",
    "        if self.verbose:\n",
    "            print(f\"{self.index}st time_info: {time_info}\")\n",
    "            # print(f\"get_time: {self.audio_stream.get_time()}\")\n",
    "            # print(f\"{self.index}st frame has arrived: {time.time()}\")\n",
    "\n",
    "        self.buffer.put(data)\n",
    "\n",
    "        query_audio = np.frombuffer(data, dtype=np.float32)\n",
    "        # print(f\"query_audio: min({np.min(query_audio)}) ~ max({np.max(query_audio)})\")\n",
    "        query_chroma_stft = librosa.feature.chroma_stft(\n",
    "            y=query_audio, hop_length=HOP_LENGTH, n_fft=N_FFT\n",
    "        )\n",
    "        if self.last_chunk is None:  # first audio chunk is given\n",
    "            current_chunk = {\n",
    "                \"timestamp\": time_info[\"input_buffer_adc_time\"],\n",
    "                \"chroma_stft\": query_chroma_stft[:, :-1],\n",
    "            }\n",
    "            self.chroma_buffer.put(current_chunk)\n",
    "            # self.chroma_buffer.put(query_chroma_stft[:, :-1])  # pop last frame converted with zero padding\n",
    "        else:\n",
    "            override_previous_padding = librosa.feature.chroma_stft(\n",
    "                y=np.concatenate((self.last_chunk, query_audio[:HOP_LENGTH])),\n",
    "                sr=self.sample_rate,\n",
    "                hop_length=HOP_LENGTH,\n",
    "                n_fft=N_FFT,\n",
    "            )[:, 1:-1]  # drop first and last frame converted with zero padding\n",
    "            accumulated_chroma = np.concatenate((override_previous_padding, query_chroma_stft[:, 1:-1]), axis=1)\n",
    "            current_chunk = {\n",
    "                \"timestamp\": time_info[\"input_buffer_adc_time\"] + HOP_LENGTH / SAMPLE_RATE,\n",
    "                \"chroma_stft\": accumulated_chroma,\n",
    "            }\n",
    "            self.chroma_buffer.put(current_chunk)\n",
    "        print(f\"[PUT] for {self.index}st frame\")\n",
    "        print(f\"queue inside at {self.index}: {self.chroma_buffer.qsize()}\")\n",
    "        self.last_chunk = query_audio[query_audio.shape[0] - HOP_LENGTH:]\n",
    "        self.index += 1\n",
    "        return (data, pyaudio.paContinue)\n",
    "\n",
    "    def run(self):\n",
    "        self.audio_interface = pyaudio.PyAudio()\n",
    "        self.audio_stream = self.audio_interface.open(\n",
    "            format=self.format,\n",
    "            channels=self.channels,\n",
    "            rate=self.sample_rate,\n",
    "            input=True,\n",
    "            frames_per_buffer=self.chunk_size,\n",
    "            stream_callback=self._process_frame,\n",
    "        )\n",
    "        self.is_mic_open = True\n",
    "        self.audio_stream.start_stream()\n",
    "        self.start_time = self.audio_stream.get_time()\n",
    "        print(\"* Recording in progress....\")\n",
    "\n",
    "    def stop(self):\n",
    "        if self.is_mic_open:\n",
    "            self.audio_stream.stop_stream()\n",
    "            self.audio_stream.close()\n",
    "            self.is_mic_open = False\n",
    "            self.audio_interface.terminate()\n",
    "            print(\"Recording Stopped.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RECORD_SECONDS = 3\n",
    "CHUNK_SIZE = 2048\n",
    "\n",
    "chunks = np.array([])\n",
    "query_chroma_stft = np.array([])\n",
    "\n",
    "ref_audio, ref_sr = librosa.load(\"../resources/audio/target/Haydn_Hob.XVI34_1-1.wav\")\n",
    "ref_chroma_stft = librosa.feature.chroma_stft(y=ref_audio, sr=ref_sr, hop_length=HOP_LENGTH, n_fft=N_FFT)\n",
    "cost_matrix = None\n",
    "step_index_matrix = None\n",
    "warping_path = None\n",
    "chroma_first_stft = None\n",
    "\n",
    "sp = StreamProcessor(SAMPLE_RATE, CHUNK_SIZE)\n",
    "sp.run()\n",
    "\n",
    "start = time.time()\n",
    "# for _ in range(int(SAMPLE_RATE / CHUNK_SIZE * RECORD_SECONDS)):\n",
    "for _ in range(1):\n",
    "    latest_chunk = sp.chroma_buffer.get()  # (12, 8)\n",
    "    print(f\"latest chunk: {latest_chunk['timestamp'], latest_chunk['chroma_stft'].shape}\")\n",
    "    break\n",
    "\n",
    "sp.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.min(ref_audio), np.max(ref_audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from synctoolbox.dtw.mrmsdtw import sync_via_mrmsdtw\n",
    "\n",
    "wp = sync_via_mrmsdtw(f_chroma1=ref_chroma_stft[:, :8],\n",
    "                    f_chroma2=chroma_first_stft,\n",
    "                    input_feature_rate=feature_rate,\n",
    "                    verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DTW Section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# librosa test\n",
    "\n",
    "RECORD_SECONDS = 11\n",
    "CHUNK_SIZE = 1024\n",
    "WINSIZE = 120 # 120 * 256 / 22050 seconds\n",
    "\n",
    "chunks = np.array([])\n",
    "\n",
    "ref_audio, ref_sr = librosa.load(\"../resources/audio/target/Haydn_Hob.XVI34_1-1.wav\")\n",
    "ref_chroma_stft = librosa.feature.chroma_stft(y=ref_audio, sr=ref_sr, hop_length=HOP_LENGTH, n_fft=N_FFT)\n",
    "\n",
    "cost_matrix = np.zeros((WINSIZE, WINSIZE))\n",
    "cost_matrix_offset = (0, 0) # (ref, query)\n",
    "warping_path = None\n",
    "ref_pointer = None\n",
    "query_pointer = None\n",
    "q_index = 0\n",
    "total_quary_chroma = np.zeros((12, MAX_LEN))\n",
    "\n",
    "sp = StreamProcessor(SAMPLE_RATE, CHUNK_SIZE)\n",
    "sp.run()\n",
    "\n",
    "start = time.time()\n",
    "# for i in range(int(SAMPLE_RATE / CHUNK_SIZE * RECORD_SECONDS)):\n",
    "for i in range(10):\n",
    "    try:\n",
    "        qsize = sp.chroma_buffer.qsize()\n",
    "        print(f\"qsize : {qsize}\")\n",
    "        \n",
    "        if qsize <= 1:\n",
    "            chroma_stft = sp.chroma_buffer.get()['chroma_stft']\n",
    "            # try:\n",
    "            #     chroma_stft = sp.chroma_buffer.get(block=False)['chroma_stft']\n",
    "            # except Exception:\n",
    "            #     time.sleep(0.1)\n",
    "            #     continue\n",
    "        else:\n",
    "            print(f\"qsize more than 1!\")\n",
    "            chroma_stfts = [sp.chroma_buffer.get()['chroma_stft'] for _ in range(qsize)]  # (12, 8) * qsize\n",
    "            chroma_stft = np.hstack(chroma_stfts)\n",
    "\n",
    "        q_length = chroma_stft.shape[1]\n",
    "        total_quary_chroma[:, q_index:q_index + q_length] = chroma_stft\n",
    "        q_index += q_length\n",
    "        \n",
    "        print(f\"[GET] {i}st frame, q_length: {q_length}\")\n",
    "        time.sleep(0.1)\n",
    "    except Exception:\n",
    "        break\n",
    "    # try:\n",
    "    #     D, wp = librosa.sequence.dtw(\n",
    "    #         X=ref_chroma_stft[:, :query_pointer],\n",
    "    #         Y=total_quary_chroma[:, q_index],\n",
    "    #         global_constraints=True,\n",
    "    #         # subseq=True,\n",
    "    #     )\n",
    "    # except Exception as e:\n",
    "    #     print(f\"e: {str(e)}\")\n",
    "    #     break\n",
    "    # cost_matrix = D\n",
    "    # warping_path = wp\n",
    "    # last_pointer = query_pointer\n",
    "    # time.sleep(0.05 * q_index)\n",
    "\n",
    "    # print(f\"after computating {i}st frame: {time.time()}\\n\")\n",
    "\n",
    "\n",
    "end = time.time()\n",
    "sp.stop()\n",
    "duration = end - start\n",
    "print(f\"duration: {duration}\")\n",
    "print(f\"remaining qsize for chroma buffer: {sp.chroma_buffer.qsize()}\")\n",
    "\n",
    "# plt.plot(warping_path[:, 0], warping_path[:, 1])\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEN = int(1e4)\n",
    "HOP_LENGTH = 256\n",
    "\n",
    "from enum import IntEnum\n",
    "import scipy\n",
    "\n",
    "\n",
    "class Direction(IntEnum):\n",
    "    REF = 1\n",
    "    QUERY = 2\n",
    "    BOTH = REF | QUERY\n",
    "\n",
    "\n",
    "class OnlineTimeWarping:\n",
    "    def __init__(\n",
    "        self,\n",
    "        sp: StreamProcessor,\n",
    "        ref_audio_path,\n",
    "        window_size,\n",
    "        max_run_count=30,\n",
    "        hop_length=HOP_LENGTH,\n",
    "        verbose=False,\n",
    "    ):\n",
    "        self.sp = sp\n",
    "        self.window_size = window_size\n",
    "        self.max_run_count = max_run_count\n",
    "        self.hop_length = hop_length\n",
    "        self.frame_per_seg = int(sp.chunk_size / hop_length)\n",
    "        self.verbose = verbose\n",
    "        self.query_pointer = 0\n",
    "        self.ref_pointer = 0\n",
    "        self.time_length = 0\n",
    "        self.distance = 0\n",
    "        self.run_count = 0\n",
    "        self.previous_direction = None\n",
    "        self.current_query_stft = None  # (12, N)\n",
    "        self.query_stft = np.zeros((12, MAX_LEN))  # (12, n)\n",
    "        self.query_audio = np.array([])\n",
    "        self.index1s = np.array([])\n",
    "        self.index2s = np.array([])\n",
    "        self.warping_path = None\n",
    "        self.warping_path_time = None\n",
    "        self.cost_matrix = np.zeros((self.window_size, self.window_size))\n",
    "        self.dist_matrix = np.zeros((self.window_size, self.window_size))\n",
    "        self.iteration = 0\n",
    "        self.cost_matrix_offset = [0, 0] # (ref, query)\n",
    "        self.q_index = 0\n",
    "\n",
    "        self.initialize_ref_audio(ref_audio_path)\n",
    "\n",
    "    def initialize_ref_audio(self, audio_path):\n",
    "        audio_y, sr = librosa.load(audio_path)\n",
    "        self.ref_audio = audio_y\n",
    "        ref_stft = librosa.feature.chroma_stft(y=audio_y, sr=sr, hop_length=HOP_LENGTH, n_fft=N_FFT)\n",
    "        ref_len = ref_stft.shape[1]\n",
    "        truncated_len = ((ref_len - 1) // self.frame_per_seg )*self.frame_per_seg\n",
    "        self.ref_stft = ref_stft[:, :truncated_len]\n",
    "\n",
    "    def init_path_cost(self):\n",
    "        print('init')\n",
    "        query_stft_seg = self.query_stft[:, :self.query_pointer] # [F, N] \n",
    "        ref_stft_seg = self.ref_stft[:, :self.ref_pointer] # [F, M]\n",
    "        dist = scipy.spatial.distance.cdist(ref_stft_seg.T, query_stft_seg.T)\n",
    "        print(ref_stft_seg.shape, query_stft_seg.shape, dist.shape)\n",
    "        self.dist_matrix[:self.ref_pointer, :self.query_pointer] = dist\n",
    "\n",
    "    def update_path_cost(self, direction):\n",
    "        x = self.ref_pointer\n",
    "        y = self.query_pointer\n",
    "        w = self.window_size\n",
    "        d = self.frame_per_seg\n",
    "        x0 = self.cost_matrix_offset[0]\n",
    "        y0 = self.cost_matrix_offset[1]\n",
    "\n",
    "        print(f\"direction: {direction}\")\n",
    "        def _shift_matrix(direction):\n",
    "            if direction == Direction.BOTH:\n",
    "                print('BOTH')\n",
    "                self.cost_matrix_offset[0] += d\n",
    "                self.cost_matrix_offset[1] += d\n",
    "                new_matrix = np.zeros_like(self.cost_matrix)\n",
    "                new_matrix[:-d, :-d] = self.cost_matrix[d:,d:]\n",
    "                new_d_matrix = np.zeros_like(self.dist_matrix)\n",
    "                new_d_matrix[:-d, :-d] = self.dist_matrix[d:,d:]\n",
    "            elif direction == Direction.REF:\n",
    "                print('REF')\n",
    "                self.cost_matrix_offset[0] += d\n",
    "                new_matrix = np.zeros_like(self.cost_matrix)\n",
    "                new_matrix[:-d, :] = self.cost_matrix[d:,:]\n",
    "                new_d_matrix = np.zeros_like(self.dist_matrix)\n",
    "                new_d_matrix[:-d, :] = self.dist_matrix[d:,:]\n",
    "            elif direction == Direction.QUERY:\n",
    "                print('QUERY')\n",
    "                self.cost_matrix_offset[1] += d\n",
    "                new_matrix = np.zeros_like(self.cost_matrix)\n",
    "                new_matrix[:, -d] = self.cost_matrix[:,d:]\n",
    "                new_d_matrix = np.zeros_like(self.dist_matrix)\n",
    "                new_d_matrix[:, :-d] = self.dist_matrix[:,d:]\n",
    "            self.cost_matrix = new_matrix\n",
    "            self.dist_matrix= new_d_matrix\n",
    "        if self.verbose:\n",
    "            print(\n",
    "                f\"ref_pointer: {ref_pointer}, query_pointer: {query_pointer}, ref shape: {self.ref_stft[:, :ref_pointer].shape} query shape: {self.query_stft[:, :query_pointer].shape}\"\n",
    "            )\n",
    "        print(f\"iter:{self.iteration}\")\n",
    "\n",
    "        if (x - x0 > w) or (y - y0 > w):\n",
    "            print(f\"shifted at:{x, y}\")\n",
    "            _shift_matrix(direction)\n",
    "            x0 = self.cost_matrix_offset[0]\n",
    "            y0 = self.cost_matrix_offset[1]\n",
    "        \n",
    "        if direction != Direction.QUERY:\n",
    "            query_stft_seg = self.query_stft[:, y0:y] # [F, N]\n",
    "            ref_stft_seg = self.ref_stft[:, x-d:x] # [F, M]\n",
    "            dist = scipy.spatial.distance.cdist(ref_stft_seg.T, query_stft_seg.T)\n",
    "            print(ref_stft_seg.shape, query_stft_seg.shape, dist.shape)\n",
    "            print(f\"offset? : {self.cost_matrix_offset}\")\n",
    "            self.dist_matrix[-d:, :y-y0] = dist\n",
    "        if direction != Direction.REF:\n",
    "            query_stft_seg = self.query_stft[:, y-d:y] # [F, N]\n",
    "            ref_stft_seg = self.ref_stft[:, x0:x] # [F, M]\n",
    "            dist = scipy.spatial.distance.cdist(ref_stft_seg.T, query_stft_seg.T)\n",
    "            print(ref_stft_seg.shape, query_stft_seg.shape, dist.shape)\n",
    "            print(f\"offset? : {self.cost_matrix_offset}\")\n",
    "            self.dist_matrix[:, -d:] = dist\n",
    "            # self.dist_matrix[:, self.query_pointer-self.frame_per_seg-self.cost_matrix_offset[1]:self.query_pointer-self.cost_matrix_offset[1]] = dist\n",
    "\n",
    "    def select_next_direction(self):\n",
    "        '''\n",
    "        if self.run_count > self.max_run_count:\n",
    "            if self.previous_direction == Direction.REF:\n",
    "                next_direction = Direction.QUERY\n",
    "            else:\n",
    "                next_direction = Direction.REF\n",
    "\n",
    "        last_ref_path, last_query_path = self.warping_path[0]\n",
    "        if (\n",
    "            last_ref_path + 1 == self.ref_pointer\n",
    "            and last_query_path + 1 == self.query_pointer\n",
    "        ):\n",
    "            next_direction = Direction.BOTH\n",
    "        elif last_ref_path < last_query_path:\n",
    "            next_direction = Direction.QUERY\n",
    "        elif last_ref_path == last_query_path:\n",
    "            next_direction = Direction.BOTH\n",
    "        else:\n",
    "            next_direction = Direction.REF\n",
    "\n",
    "        return next_direction\n",
    "        '''\n",
    "        return Direction.BOTH\n",
    "\n",
    "    def get_new_input(self):\n",
    "        qsize = self.sp.chroma_buffer.qsize()\n",
    "        if qsize <= 1:\n",
    "            query_chroma_stft = self.sp.chroma_buffer.get()['chroma_stft']\n",
    "        else:\n",
    "            print(f\"qsize more than 1!\")\n",
    "            chroma_stfts = [self.sp.chroma_buffer.get()['chroma_stft'] for _ in range(qsize)]  # (12, 4) * qsize\n",
    "            query_chroma_stft = np.hstack(chroma_stfts)\n",
    "        self.current_query_stft = query_chroma_stft\n",
    "        q_length = query_chroma_stft.shape[1]\n",
    "        self.query_stft[:, self.q_index:self.q_index + q_length] = query_chroma_stft\n",
    "        self.q_index += q_length\n",
    "\n",
    "        # qsize = self.sp.chroma_buffer.qsize()\n",
    "        # if qsize <= 1:\n",
    "        #     query_chroma_stft = self.sp.chroma_buffer.get()\n",
    "        # else:\n",
    "        #     query_chroma_stft = np.hstack([self.sp.chroma_buffer.get() for _ in range(qsize)])\n",
    "        # self.current_query_stft = query_chroma_stft\n",
    "        # self.time_length = self.current_query_stft.shape[1]\n",
    "\n",
    "        # self.query_stft = (\n",
    "        #     np.concatenate((self.query_stft, self.current_query_stft), axis=1)\n",
    "        #     if self.query_stft.any()\n",
    "        #     else self.current_query_stft\n",
    "        # )\n",
    "\n",
    "    def run(self):\n",
    "        self.sp.run()  # mic ON\n",
    "        # self.query_pointer += int(CHUNK_SIZE / HOP_LENGTH * self.window_size)\n",
    "        # self.ref_pointer += int(CHUNK_SIZE / HOP_LENGTH * self.window_size)\n",
    "\n",
    "        self.ref_pointer += self.window_size\n",
    "        start_time = time.time()\n",
    "        self.get_new_input()\n",
    "        self.query_pointer += self.frame_per_seg\n",
    "\n",
    "        self.init_path_cost()\n",
    "        # while self.sp.is_mic_open:\n",
    "        while (time.time() - start_time < 5) and (self.ref_pointer<=(self.ref_stft.shape[1]-self.frame_per_seg)):\n",
    "            direction = self.select_next_direction()\n",
    "            if direction is Direction.QUERY:\n",
    "                self.query_pointer += self.frame_per_seg\n",
    "                self.get_new_input()\n",
    "                self.update_path_cost(direction)\n",
    "\n",
    "            elif direction is Direction.REF:\n",
    "                self.ref_pointer += self.frame_per_seg\n",
    "                self.update_path_cost(direction)\n",
    "\n",
    "            elif direction is Direction.BOTH:\n",
    "                self.query_pointer += self.frame_per_seg\n",
    "                self.ref_pointer += self.frame_per_seg\n",
    "                self.update_path_cost(direction)\n",
    "\n",
    "            if self.select_next_direction() == self.previous_direction:\n",
    "                self.run_count += 1\n",
    "            else:\n",
    "                self.run_count = 1\n",
    "\n",
    "            if direction is not Direction.BOTH:\n",
    "                self.previous_direction = direction\n",
    "            self.iteration += 1\n",
    "\n",
    "        end_time = time.time()\n",
    "        print(f\"duration: {end_time - start_time}\")\n",
    "        self.sp.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_audio_path = \"../resources/audio/align/Happy_Birthday_To_You_C_Major.wav\"\n",
    "SAMPLE_RATE = 22050\n",
    "CHUNK_SIZE = 1024\n",
    "N_FFT = 512\n",
    "import traceback\n",
    "\n",
    "sp = StreamProcessor(SAMPLE_RATE, CHUNK_SIZE)\n",
    "odtw = OnlineTimeWarping(sp, ref_audio_path, window_size=120)\n",
    "try:\n",
    "    odtw.run()\n",
    "except Exception as e:\n",
    "    print(f\"error! : {str(e)}, {type(e)}\")\n",
    "    traceback.print_tb(e.__traceback__)\n",
    "    sp.stop()\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(odtw.ref_pointer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.imshow(odtw.dist_matrix.T, aspect='auto', origin='lower')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(odtw.query_stft[:,:odtw.ref_pointer], aspect='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(odtw.ref_stft, aspect='auto')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
  },
  "kernelspec": {
   "display_name": "imp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
